{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ecef64",
   "metadata": {},
   "source": [
    "## Toy example: Inferring the mean of Gaussians\n",
    "\n",
    "#### comparing the multi-round SNPE approach against our new incremental approach.\n",
    "\n",
    "Goal of this little toy example is to show that provided our parameters are independent of each other, we need less simulations to derive a good approximation of our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd32f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code/')\n",
    "\n",
    "import utils\n",
    "from utils.helpers import get_time\n",
    "from utils import inference\n",
    "\n",
    "from utils.sbi_modulated_functions import Combined\n",
    "\n",
    "\n",
    "from utils.helpers import get_time\n",
    "\n",
    "from utils.simulation_wrapper import SimulationWrapper\n",
    "\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.inference import SNPE_C\n",
    "\n",
    "import sbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb05c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.2\n"
     ]
    }
   ],
   "source": [
    "print(sbi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c8ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def Gaussian(thetas, normal_noise=0.1):\n",
    "    \n",
    "    gauss_list = []\n",
    "    \n",
    "    for theta in thetas:\n",
    "    \n",
    "        mu, sigma = theta, normal_noise # mean and standard deviation\n",
    "\n",
    "        s = np.random.normal(mu, sigma, 1)\n",
    "        \n",
    "        gauss_list.append(s[0])\n",
    "        \n",
    "    gauss_obs = torch.tensor(gauss_list)\n",
    "    \n",
    "    return gauss_obs\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8d549",
   "metadata": {},
   "source": [
    "### Calculate posterior for different number of simulations: 1k,  3k, 5k, 10k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06b59c",
   "metadata": {},
   "source": [
    "### starting with multi-round snpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a908c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_thetas = torch.Tensor([[3, 6, 20, 10, 90, 55, 27, 27, 4, 70, 5, 66, 99, 40, 45]])\n",
    "parameter_names = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13', 't14', 't15']\n",
    "\n",
    "prior_max = [100] * 15\n",
    "prior_min = [0] * 15\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2af52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225b550613924f84ba3ff7584448fd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 150 simulations in 150 batches.:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 43 epochs.for round  0  time is:  0:00:04.414578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75097e48dd9d4c579344af7bca397404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 150 posterior samples:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b4058d73d940338244300caf2be8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 150 simulations in 150 batches.:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with non-atomic loss\n",
      " Neural network successfully converged after 31 epochs.for round  1  time is:  0:00:08.261546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c9ad4377f54016b97c0583ab2cde9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 150 posterior samples:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4ec43f9edf4ef5a862d8c2b3ed1839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 150 simulations in 150 batches.:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with non-atomic loss\n",
      " Neural network successfully converged after 23 epochs.for round  2  time is:  0:00:06.345000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb9332699bc4e3faffdbe9be636f9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 300 posterior samples:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8161417ed24045348b59192d2eba22ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 300 simulations in 300 batches.:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with non-atomic loss\n",
      " Training neural network. Epochs trained: 16"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN/Inf present in proposal posterior eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3691254/1442009662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_simulations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdensity_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/inference/snpe/snpe_c.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_atoms, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, exclude_invalid_x, resume_training, discard_prior_samples, use_combined_loss, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_state_for_mog_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_state_for_mog_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/inference/snpe/snpe_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, exclude_invalid_x, resume_training, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 train_losses = self._loss(\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mtheta_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibration_kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                 )\n\u001b[1;32m    288\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/inference/snpe/snpe_base.py\u001b[0m in \u001b[0;36m_loss\u001b[0;34m(self, theta, x, masks, proposal, calibration_kernel)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob_proposal_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibration_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/inference/snpe/snpe_c.py\u001b[0m in \u001b[0;36m_log_prob_proposal_posterior\u001b[0;34m(self, theta, x, masks, proposal)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_non_atomic_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob_proposal_posterior_mog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob_proposal_posterior_atomic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/inference/snpe/snpe_c.py\u001b[0m in \u001b[0;36m_log_prob_proposal_posterior_mog\u001b[0;34m(self, theta, x, proposal)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_pp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         )\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_proposal_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"proposal posterior eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_prob_proposal_posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sbi/sbi/utils/torchutils.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(quantity, description)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"NaN/Inf present in {description}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: NaN/Inf present in proposal posterior eval."
     ]
    }
   ],
   "source": [
    "num_simulations_list = [150, 300]\n",
    "\n",
    "prior = utils.torchutils.BoxUniform(low=prior_min, high = prior_max)\n",
    "inf = SNPE_C(prior, density_estimator=\"mdn\")\n",
    "simulator_stats, prior = prepare_for_sbi(Gaussian, prior)\n",
    "\n",
    "proposal = prior\n",
    "\n",
    "posterior_snpe_list = []\n",
    "\n",
    "\n",
    "\n",
    "for num_simulations in num_simulations_list:\n",
    "\n",
    "    for i in range(3):\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        theta, x = simulate_for_sbi(\n",
    "            simulator_stats,\n",
    "            proposal=proposal,\n",
    "            num_simulations=num_simulations,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "        inf = inf.append_simulations(theta, x, proposal=proposal)\n",
    "        density_estimator = inf.train()\n",
    "\n",
    "        posterior = inf.build_posterior(density_estimator)\n",
    "\n",
    "        obs_real = Gaussian(true_thetas[0])\n",
    "\n",
    "\n",
    "        proposal = posterior.set_default_x(obs_real)\n",
    "        \n",
    "        finish_time = datetime.datetime.now()\n",
    "\n",
    "        diff_time_snpe = finish_time - start_time\n",
    "        \n",
    "        print('for round ',i, ' time is: ', diff_time_snpe)\n",
    "\n",
    "    posterior_snpe = posterior\n",
    "    \n",
    "    posterior_snpe_list.append(posterior_snpe)\n",
    "    \n",
    "finish_time = datetime.datetime.now()\n",
    "\n",
    "diff_time_snpe = finish_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc1fc433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:57:44.220780\n"
     ]
    }
   ],
   "source": [
    "print(diff_time_snpe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
