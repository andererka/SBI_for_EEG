{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc7403",
   "metadata": {},
   "source": [
    "# Exploring parameters\n",
    "\n",
    "#### density plots, post predictive checks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e788d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path as op\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, jones_2009_model\n",
    "from hnn_core.viz import plot_dipole\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "sys.path.append('../code/utils/')\n",
    "#sys.path.append('../code/sbi/')\n",
    "#sys.path.append('../../results_cluster/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/sbi_for_eeg_data/code/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "#from utils.plot import cov, compare_vars, plot_varchanges\n",
    "#from utils.plot import compare_KLs, plot_KLs\n",
    "#from sbi.inference import potentials\n",
    "import utils.sbi_modulated_functions\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "\n",
    "from sbi.analysis import conditional_pairplot, conditional_corrcoeff\n",
    "\n",
    "\n",
    "\n",
    "# import the summary statistics that you want to investigate\n",
    "from summary_features.calculate_summary_features import calculate_summary_statistics_alternative as alternative_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal as temporal_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_number as number_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab993458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c212ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining neuronal network model\n",
    "\n",
    "num_params = 17\n",
    "\n",
    "from utils.simulation_wrapper import set_network_default, SimulationWrapper\n",
    "sim_wrapper = SimulationWrapper(num_params, noise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 30\n",
    "\n",
    "if num_params == 6:\n",
    "    \n",
    "    prior_min_fix = [0.0, 11.3, 0.0, 43.8, 0.0, 89.491]\n",
    "    prior_max_fix = [0.160, 35.9, 0.821, 79.0, 8.104, 162.110]\n",
    "\n",
    "    prior_min = [0.0, 11.3, 0.0, 43.8, 0.0, 89.491]\n",
    "    prior_max = [0.160, 35.9, 0.821, 79.0, 8.104, 162.110]\n",
    "    #true_params = torch.tensor([[26.61, 63.53,  137.12]])\n",
    "    true_params = torch.tensor([[0.0274, 19.01, 0.1369, 61.89, 0.1435, 120.86]])\n",
    "\n",
    "    \n",
    "\n",
    "if num_params == 25:\n",
    "    prior_min = [0, 0, 0, 0, 0, 0, 0, 0, 13.3,    # prox1 weights\n",
    "                 0, 0, 0, 0, 0, 0, 51.980,            # distal weights\n",
    "                 0, 0, 0, 0, 0, 0, 0, 0, 112.13]       # prox2 weights\n",
    "\n",
    "\n",
    "    # ampa, nmda [0.927, 0.160, 2.093, 0.0519,        1.0, 1.0, 1.0, 1.0, 35.9,\n",
    "    #           0.0394, 0.000042, 0.039372,           0.854, 0.117,  0.480, 75.08,\n",
    "    #            0.000018, 8.633, 0.05375, 4.104,     1.0, 1.0, 1.0, 1.0, 162.110]\n",
    "\n",
    "    prior_max = [0.927, 1.0, 0.160, 1.0,  2.093, 1.0, 0.0519, 1.0, 35.9,\n",
    "                 0.0394, 0.117, 0.000042, 0.025902, 0.854, 0.480, 75.08,\n",
    "                 0.000018, 1.0, 8.633, 1.0, 0.05375, 1.0, 4.104,  1.0, 162.110]\n",
    "\n",
    "    true_params = torch.tensor([[0.277, 0.3739, 0.0399, 0.0, 0.6244, 0.3739, 0.034, 0.0, 18.977,\n",
    "                                 0.011467, 0.06337, 0.000012, 0.013407, 0.466095, 0.0767, 63.08,\n",
    "                                 0.000005, 0.116706, 4.6729, 0.016733, 0.011468, 0.061556, 2.33, 0.0679, 120.86]])\n",
    "    \n",
    "if num_params == 17:\n",
    "    \n",
    "    prior_min = [0, 0, 0, 0, 0, 13.3,  0, 0, 0, 0, 0, 51.980, 0, 0, 0, 0, 112.13]\n",
    "    prior_max = [0.927, 0.160, 2.093, 1.0, 1.0, 35.9, 0.000042, 0.039372, 0.025902,  0.480, 0.117, 75.08, 8.633, 4.104, 1.0, 1.0, 162.110]\n",
    "\n",
    "    true_params = torch.tensor([[0.277, 0.0399, 0.6244, 0.3739, 0.0, 18.977, 0.000012, 0.0115, 0.0134,  0.0767, 0.06337, 63.08, 4.6729, 2.33, 0.016733, 0.0679, 120.86]])\n",
    "\n",
    "\n",
    "prior = utils.torchutils.BoxUniform(low=prior_min, high=prior_max)\n",
    "\n",
    "#number_simulations = 10\n",
    "density_estimator = 'nsf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5528677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#assert (prior.event_shape==torch.Size([25]))\n",
    "from utils import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230edc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu\n",
      "/home/ubuntu/results\n"
     ]
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "import pickle\n",
    "from data_load_writer import *\n",
    "from data_load_writer import load_from_file as lf\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "#os.chdir('/home/kathi/Documents/Master_thesis/results_cluster/')\n",
    "\n",
    "\n",
    "\n",
    "#print(os.getcwd())\n",
    "\n",
    "#os.chdir('/home/kathi/Documents/Master_thesis/results_cluster')\n",
    "\n",
    "## loading simulations from previously saved computations\n",
    "#file = 'ERP_sequential_3params/step3'\n",
    "#file = 'ERP_save_sim_nsf_num_params3'\n",
    "#file = 'eval_features'\n",
    "#file = '10000_multi_round_num_params_25newparams'\n",
    "\n",
    "file = 'multi_round_17params'\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('results')\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "  \n",
    "\n",
    "#thetas = torch.load('{}/thetas.pt'.format(file))\n",
    "\n",
    "posterior = torch.load('{}/posterior.pt'.format(file))\n",
    "\n",
    "#neural_dens = torch.load('{}/neural_dens.pt'.format(file))\n",
    "#x_without = torch.load('{}/obs_without.pt'.format(file))\n",
    "\n",
    "#x = calculate_summary_stats_temporal(x_without)\n",
    "\n",
    "\n",
    "#true_params = torch.tensor([[0.0274, 19.01, 0.1369, 61.89, 0.1435, 120.86]])\n",
    "#true_params = torch.tensor([[  18.9700, 63.5300, 137.1200]])\n",
    "#true_params = torch.load('results/{}/true_params.pt'.format(file))\n",
    "#true_params = torch.tensor([[0.277, 0.0399, 0.3739, 0.034, 18.977, 0.0115, 0.000012, 0.466, 0.06337, 0.0134, 0.0766, 63.08, 0.000005, 4.6729, 0.0115, 0.3308, 120.86]])\n",
    "\n",
    "#posteriors_round =  torch.load('{}/posteriors_each_round.pt'.format(file))\n",
    "obs_real = torch.load('{}/obs_real.pt'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20447a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7605ff519942e5a64518692154c678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 100 posterior samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 100 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate:  0.0\n",
      "acceptance rate:  4.9751243781094526e-05\n",
      "acceptance rate:  9.966777408637874e-05\n",
      "acceptance rate:  9.975062344139652e-05\n",
      "acceptance rate:  0.00011976047904191617\n",
      "acceptance rate:  9.983361064891847e-05\n",
      "acceptance rate:  9.985734664764622e-05\n",
      "acceptance rate:  9.987515605493134e-05\n",
      "acceptance rate:  0.00011098779134295228\n",
      "acceptance rate:  0.00010989010989010989\n",
      "acceptance rate:  9.990917347865577e-05\n",
      "acceptance rate:  9.991673605328893e-05\n",
      "acceptance rate:  9.223674096848578e-05\n",
      "acceptance rate:  8.565310492505354e-05\n",
      "acceptance rate:  7.994670219853431e-05\n",
      "acceptance rate:  7.495315427857589e-05\n",
      "acceptance rate:  7.054673721340387e-05\n",
      "acceptance rate:  7.773459189339256e-05\n"
     ]
    }
   ],
   "source": [
    "#obs_real_stat2 = calculate_summary_stats_temporal(obs_real[0])\n",
    "\n",
    "samples = posterior.sample((100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [\"prox1_ampa_l2_bas\",\"prox1_ampa_l2_pyr\",\"prox1_ampa_l5_bas\",\"prox1_nmda_l5_bas\", \"prox1_nmda_l5_pyr\",\n",
    " \"t_prox1\",\n",
    " \"dist_ampa_l2_pyr\",\"dist_ampa_l2_bas\",\"dist_nmda_l2_pyr\",\n",
    " \"dist_nmda_l5_pyr\",\"dist_nmda_l2_bas\",\n",
    " \"t_dist\", \n",
    " \"prox2_ampa_l2_pyr\",\"prox2_ampa_l5_pyr\",\"prox2_nmda_l2_pyr\",\"prox2_nmda_l5_pyr\",\n",
    " \"t_prox2\"]\n",
    "\n",
    "if num_params ==6:\n",
    "    parameter_names = [\"prox_1_ampa_l2_pyr\",\n",
    "     \"t_evprox_1\",\n",
    "     \"dist_nmda_l2_pyr\",\n",
    "     \"t_evdist_1\", \n",
    "     \"prox_2_ampa_l5_pyr\",\n",
    "     \"t_evprox_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x = inference.run_only_sim(samples, simulation_wrapper=sim_wrapper, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbdbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sample from prior now\n",
    "num_samples = 100\n",
    "samples_prior = []\n",
    "\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = prior.sample()\n",
    "    samples_prior.append(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "s_x_prior = inference.run_only_sim(samples_prior, sim_wrapper, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7dcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x_torch = torch.stack(([s_x[i] for i in range(39)]))\n",
    "s_x_prior_torch = torch.stack(([s_x_prior[i] for i in range(39)]))\n",
    "\n",
    "\n",
    "mean = torch.mean(s_x_torch, 0)\n",
    "std = torch.std(s_x_torch, 0)\n",
    "\n",
    "mean_prior = torch.mean(s_x_prior_torch, 0)\n",
    "std_prior = torch.std(s_x_prior_torch, 0)\n",
    "\n",
    "lower = mean - 1.96 * std\n",
    "\n",
    "\n",
    "upper = mean + 1.96 * std\n",
    "\n",
    "\n",
    "lower_prior = mean_prior - 1.96 * std_prior\n",
    "\n",
    "\n",
    "upper_prior = mean_prior + 1.96 * std_prior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_real = torch.load('{}/obs_real.pt'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92037c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set() \n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "#sns.set_style('ticks')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "fig1, ax = plt.subplots(1, 1)\n",
    "#ax.set_title(\"Comparing signal\")\n",
    "\n",
    "    \n",
    "plt.plot(mean, color ='blue', label='mean of posterior')\n",
    "\n",
    "for s in s_x[0:40]:\n",
    "    plt.plot(s, alpha=0.05, color='blue')\n",
    "    #plt.ylim(-30,30)\n",
    "    plt.xlim(0, 7000)\n",
    "\n",
    "plt.plot(lower, color='blue', linestyle='dashed', label='95% confidence')\n",
    "plt.plot(upper, color='blue', linestyle='dashed')\n",
    "plt.fill_between(x= torch.arange(len(mean_prior)), y1=lower, y2=upper, color='blue', alpha=0.1)\n",
    "plt.xlim(0, 7000)\n",
    "plt.ylim(-100, 200)\n",
    "\n",
    "\n",
    "plt.plot(mean_prior, color ='orange', label='mean of prior')\n",
    "\n",
    "\n",
    "for x_w in s_x_prior[0:40]:\n",
    "    plt.plot(x_w, alpha=0.05, color='orange')\n",
    "\n",
    "plt.plot(lower_prior, color='orange', linestyle='dashed', label='95% confidence')\n",
    "plt.plot(upper_prior, color='orange', linestyle='dashed')\n",
    "plt.fill_between(x= torch.arange(len(mean_prior)), y1=lower_prior, y2=upper_prior, color='orange', alpha=0.2)\n",
    "plt.xlim(0, 7000)\n",
    "\n",
    "plt.xlabel('time in ms')\n",
    "#plt.ylabel('voltage ()')\n",
    "\n",
    "fig1.gca().set_ylabel(r'voltage ($\\mu V$)')\n",
    "    \n",
    "plt.plot(obs_real, label='Ground truth', color='red', linewidth=0.5)\n",
    "\n",
    "plt.xticks([1000, 2000, 3000, 4000, 5000, 6000],[33, 66, 100, 133, 166, 200])\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_real = torch.load('{}/obs_real.pt'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df01ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.save('thesis_4_7.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
