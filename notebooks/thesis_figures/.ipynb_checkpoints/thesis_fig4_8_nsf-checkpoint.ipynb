{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc7403",
   "metadata": {},
   "source": [
    "# Exploring parameters\n",
    "\n",
    "#### density plots, post predictive checks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e788d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path as op\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, jones_2009_model\n",
    "from hnn_core.viz import plot_dipole\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "sys.path.append('../code/utils/')\n",
    "#sys.path.append('../code/sbi/')\n",
    "#sys.path.append('../../results_cluster/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/sbi_for_eeg_data/code/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "#from utils.plot import cov, compare_vars, plot_varchanges\n",
    "#from utils.plot import compare_KLs, plot_KLs\n",
    "#from sbi.inference import potentials\n",
    "import utils.sbi_modulated_functions\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "\n",
    "from sbi.analysis import conditional_pairplot, conditional_corrcoeff\n",
    "\n",
    "\n",
    "\n",
    "# import the summary statistics that you want to investigate\n",
    "from summary_features.calculate_summary_features import calculate_summary_statistics_alternative as alternative_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal as temporal_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_number as number_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab993458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c212ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining neuronal network model\n",
    "\n",
    "num_params = 17\n",
    "\n",
    "from utils.simulation_wrapper import set_network_default, SimulationWrapper\n",
    "sim_wrapper = SimulationWrapper(num_params, noise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b287160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 30\n",
    "\n",
    "if num_params == 6:\n",
    "    \n",
    "    prior_min_fix = [0.0, 11.3, 0.0, 43.8, 0.0, 89.491]\n",
    "    prior_max_fix = [0.160, 35.9, 0.821, 79.0, 8.104, 162.110]\n",
    "\n",
    "    prior_min = [0.0, 11.3, 0.0, 43.8, 0.0, 89.491]\n",
    "    prior_max = [0.160, 35.9, 0.821, 79.0, 8.104, 162.110]\n",
    "    #true_params = torch.tensor([[26.61, 63.53,  137.12]])\n",
    "    true_params = torch.tensor([[0.0274, 19.01, 0.1369, 61.89, 0.1435, 120.86]])\n",
    "\n",
    "    \n",
    "\n",
    "if num_params == 25:\n",
    "    prior_min = [0, 0, 0, 0, 0, 0, 0, 0, 13.3,    # prox1 weights\n",
    "                 0, 0, 0, 0, 0, 0, 51.980,            # distal weights\n",
    "                 0, 0, 0, 0, 0, 0, 0, 0, 112.13]       # prox2 weights\n",
    "\n",
    "\n",
    "    # ampa, nmda [0.927, 0.160, 2.093, 0.0519,        1.0, 1.0, 1.0, 1.0, 35.9,\n",
    "    #           0.0394, 0.000042, 0.039372,           0.854, 0.117,  0.480, 75.08,\n",
    "    #            0.000018, 8.633, 0.05375, 4.104,     1.0, 1.0, 1.0, 1.0, 162.110]\n",
    "\n",
    "    prior_max = [0.927, 1.0, 0.160, 1.0,  2.093, 1.0, 0.0519, 1.0, 35.9,\n",
    "                 0.0394, 0.117, 0.000042, 0.025902, 0.854, 0.480, 75.08,\n",
    "                 0.000018, 1.0, 8.633, 1.0, 0.05375, 1.0, 4.104,  1.0, 162.110]\n",
    "\n",
    "    true_params = torch.tensor([[0.277, 0.3739, 0.0399, 0.0, 0.6244, 0.3739, 0.034, 0.0, 18.977,\n",
    "                                 0.011467, 0.06337, 0.000012, 0.013407, 0.466095, 0.0767, 63.08,\n",
    "                                 0.000005, 0.116706, 4.6729, 0.016733, 0.011468, 0.061556, 2.33, 0.0679, 120.86]])\n",
    "    \n",
    "if num_params == 17:\n",
    "    \n",
    "    prior_min = [0, 0, 0, 0, 0, 13.3,  0, 0, 0, 0, 0, 51.980, 0, 0, 0, 0, 112.13]\n",
    "    prior_max = [0.927, 0.160, 2.093, 1.0, 1.0, 35.9, 0.000042, 0.039372, 0.025902,  0.480, 0.117, 75.08, 8.633, 4.104, 1.0, 1.0, 162.110]\n",
    "\n",
    "    true_params = torch.tensor([[0.277, 0.0399, 0.6244, 0.3739, 0.0, 18.977, 0.000012, 0.0115, 0.0134,  0.0767, 0.06337, 63.08, 4.6729, 2.33, 0.016733, 0.0679, 120.86]])\n",
    "\n",
    "\n",
    "prior = utils.torchutils.BoxUniform(low=prior_min, high=prior_max)\n",
    "\n",
    "#number_simulations = 10\n",
    "density_estimator = 'nsf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5528677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#assert (prior.event_shape==torch.Size([25]))\n",
    "from utils import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230edc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/results\n"
     ]
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "import pickle\n",
    "from data_load_writer import *\n",
    "from data_load_writer import load_from_file as lf\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "#file = 'multi_round'\n",
    "\n",
    "file = 'multi_round_10000_17params_nsf_fake_2104_001_std'\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('results')\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "  \n",
    "\n",
    "#thetas = torch.load('{}/thetas.pt'.format(file))\n",
    "\n",
    "posterior = torch.load('{}/posterior.pt'.format(file))\n",
    "\n",
    "#neural_dens = torch.load('{}/neural_dens.pt'.format(file))\n",
    "#x_without = torch.load('{}/obs_without.pt'.format(file))\n",
    "\n",
    "#x = calculate_summary_stats_temporal(x_without)\n",
    "\n",
    "\n",
    "#true_params = torch.tensor([[0.0274, 19.01, 0.1369, 61.89, 0.1435, 120.86]])\n",
    "#true_params = torch.tensor([[  18.9700, 63.5300, 137.1200]])\n",
    "#true_params = torch.load('results/{}/true_params.pt'.format(file))\n",
    "#true_params = torch.tensor([[0.277, 0.0399, 0.3739, 0.034, 18.977, 0.0115, 0.000012, 0.466, 0.06337, 0.0134, 0.0766, 63.08, 0.000005, 4.6729, 0.0115, 0.3308, 120.86]])\n",
    "\n",
    "#posteriors_round =  torch.load('{}/posteriors_each_round.pt'.format(file))\n",
    "#obs_real = torch.load('{}/obs_real.pt'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6f7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior = posteriors_round[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20447a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5830b8e54f8d415ca37e8da683f96168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate:  1.0\n"
     ]
    }
   ],
   "source": [
    "#obs_real_stat2 = calculate_summary_stats_temporal(obs_real[0])\n",
    "\n",
    "samples = posterior.sample((1000,), not_within_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e283b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [\"prox1_ampa_l2_bas\",\"prox1_ampa_l2_pyr\",\"prox1_ampa_l5_bas\",\"prox1_nmda_l5_bas\", \"prox1_nmda_l5_pyr\",\n",
    " \"t_prox1\",\n",
    " \"dist_ampa_l2_pyr\",\"dist_ampa_l2_bas\",\"dist_nmda_l2_pyr\",\n",
    " \"dist_nmda_l5_pyr\",\"dist_nmda_l2_bas\",\n",
    " \"t_dist\", \n",
    " \"prox2_ampa_l2_pyr\",\"prox2_ampa_l5_pyr\",\"prox2_nmda_l2_pyr\",\"prox2_nmda_l5_pyr\",\n",
    " \"t_prox2\"]\n",
    "\n",
    "if num_params ==6:\n",
    "    parameter_names = [\"prox_1_ampa_l2_pyr\",\n",
    "     \"t_evprox_1\",\n",
    "     \"dist_nmda_l2_pyr\",\n",
    "     \"t_evdist_1\", \n",
    "     \"prox_2_ampa_l5_pyr\",\n",
    "     \"t_evprox_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a180df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7006e-01, -1.3502e-01, -1.1015e+00, -6.0534e-01, -2.3195e-02,\n",
      "         1.6266e+01, -1.3825e-04, -1.1075e-01,  2.6512e-03, -9.1853e-02,\n",
      "        -1.8129e-01,  6.1440e+01, -4.8632e+00, -1.6825e+00, -5.3528e-01,\n",
      "        -3.4335e-01,  1.1684e+02])\n",
      "tensor([1.5703e+00, 2.7634e-01, 3.1982e+00, 1.3708e+00, 1.4086e-02, 2.2487e+01,\n",
      "        2.1943e-04, 1.6487e-01, 3.9447e-02, 1.6180e-01, 2.9347e-01, 6.9012e+01,\n",
      "        1.6756e+01, 6.3737e+00, 2.1602e+00, 9.7877e-01, 1.5472e+02])\n",
      "tensor([1.8404e-02, 4.1136e-03, 4.2997e-02, 1.9762e-02, 3.7281e-04, 6.2211e-02,\n",
      "        3.5768e-06, 2.7561e-03, 3.6796e-04, 2.5365e-03, 4.7476e-03, 7.5724e-02,\n",
      "        2.1619e-01, 8.0562e-02, 2.6955e-02, 1.3221e-02, 3.7884e-01])\n"
     ]
    }
   ],
   "source": [
    "##better limits:\n",
    "\n",
    "list_min = torch.min(samples, 0)[0]\n",
    "list_max = torch.max(samples, 0)[0]\n",
    "\n",
    "print(list_min)\n",
    "\n",
    "print(list_max)\n",
    "\n",
    "diff = torch.abs(list_max - list_min) * 0.01\n",
    "\n",
    "print(diff)\n",
    "\n",
    "list_min = list(torch.nn.functional.relu(list_min))\n",
    "#list_min = list(list_min - diff)\n",
    "list_max = list(list_max - diff)\n",
    "\n",
    "limits = [list(tup) for tup in zip(list_min, list_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b787dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limits = [list(tup) for tup in zip(prior_min, prior_max)]\n",
    "\n",
    "\n",
    "plt.set_cmap('viridis')\n",
    "\n",
    "fig, axes = analysis.pairplot(\n",
    "    samples,\n",
    "    limits=limits,\n",
    "    upper = 'kde',\n",
    "    lower='kde',\n",
    "    #subset=[5, 11, 16],\n",
    "    ticks=np.round(limits,2),\n",
    "    figsize=(20, 20),\n",
    "    points=true_params,\n",
    "    points_offdiag={\"markersize\": 5},\n",
    "    points_colors=\"r\",\n",
    "    labels=parameter_names,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(5):\n",
    "#    axes[i][i].xaxis.label.set_color('magenta')\n",
    "#for i in range(5, 12):\n",
    "#    axes[i][i].xaxis.label.set_color('navy')\n",
    "#for i in range(12, 17):\n",
    "#    axes[i][i].xaxis.label.set_color('deeppink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_marginal = np.corrcoef(samples.T)\n",
    "fig, ax = plt.subplots(1,1, figsize=(4, 4))\n",
    "im = plt.imshow(corr_matrix_marginal, clim=[-1, 1], cmap='PiYG')\n",
    "_ = fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3bf4664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864867005a38415f95575e26d7f14297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1 posterior samples:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 1 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n",
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 10000 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    }
   ],
   "source": [
    "condition = posterior.sample((1,))\n",
    "\n",
    "cond_coeff_mat = conditional_corrcoeff(\n",
    "    density=posterior,\n",
    "    condition=condition,\n",
    "    #limits = limits\n",
    "    limits=torch.tensor([[-2., 2.]]*17),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfbdb3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
    "im = plt.imshow(cond_coeff_mat, clim=[-1, 1], cmap='PiYG')\n",
    "_ = fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e830bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
