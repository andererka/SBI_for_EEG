{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc7403",
   "metadata": {},
   "source": [
    "# Exploring parameters\n",
    "\n",
    "#### density plots, post predictive checks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e788d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path as op\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, jones_2009_model\n",
    "from hnn_core.viz import plot_dipole\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "sys.path.append('../code/utils/')\n",
    "#sys.path.append('../code/sbi/')\n",
    "#sys.path.append('../../results_cluster/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/sbi_for_eeg_data/code/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "#from utils.plot import cov, compare_vars, plot_varchanges\n",
    "#from utils.plot import compare_KLs, plot_KLs\n",
    "#from sbi.inference import potentials\n",
    "import utils.sbi_modulated_functions\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "\n",
    "from sbi.analysis import conditional_pairplot, conditional_corrcoeff\n",
    "\n",
    "\n",
    "\n",
    "# import the summary statistics that you want to investigate\n",
    "from summary_features.calculate_summary_features import calculate_summary_statistics_alternative as alternative_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal as temporal_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_number as number_sumstats\n",
    "from summary_features.calculate_summary_features import calculate_summary_stats_temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab993458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c212ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining neuronal network model\n",
    "\n",
    "num_params = 6\n",
    "\n",
    "from utils.simulation_wrapper import set_network_default, SimulationWrapper\n",
    "sim_wrapper = SimulationWrapper(num_params, noise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230edc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu\n",
      "/home/ubuntu/results/toy_example_maf_08_04_lesser_ratio\n"
     ]
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "import pickle\n",
    "from data_load_writer import *\n",
    "from data_load_writer import load_from_file as lf\n",
    "\n",
    "import os\n",
    "\n",
    "work_dir = '/home/ubuntu/'\n",
    "\n",
    "os.chdir(work_dir)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "file = 'toy_example_maf_08_04_lesser_ratio'\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('results/{}'.format(file))\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde67830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian(thetas, normal_noise=1):\n",
    "    \n",
    "    gauss_list = []\n",
    "    \n",
    "    for theta in thetas:\n",
    "    \n",
    "        mu, sigma = theta, normal_noise # mean and standard deviation\n",
    "\n",
    "        s = np.random.normal(mu, sigma, 1)\n",
    "    \n",
    "        \n",
    "        gauss_list.append(s[0])\n",
    "        \n",
    "    gauss_obs = torch.tensor(gauss_list)\n",
    "    \n",
    "    return gauss_obs\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc10d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_collection = torch.load('list_collection.pt')\n",
    "list_collection_inc = torch.load('list_collection_inc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4ca2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_thetas = torch.tensor([[3.0, 6.0, 20.0, 10.0, 90.0, 55.0, 27.0, 27.0, 4.0, 70.0, 5.0, 66.0, 99.0, 40.0, 45.0]])\n",
    "parameter_names = ['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13', 't14', 't15']\n",
    "\n",
    "prior_max = [100.0] * 15\n",
    "prior_min = [1.0] * 15\n",
    "\n",
    "prior = utils.torchutils.BoxUniform(low=prior_min, high = prior_max)\n",
    "\n",
    "samples_prior = prior.sample((10000,))\n",
    "\n",
    "simulator_stats, prior = prepare_for_sbi(Gaussian, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64df37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_prior_list = samples_prior.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431660f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c8bddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 15])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_prior_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbeec27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "thetas = inference.run_only_sim(samples_prior_list, simulation_wrapper = simulator_stats, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b885f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "678fc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Gauss(X, Y):\n",
    "    \n",
    "    sample_x = X.sample((1000,))\n",
    "    mu_x = torch.mean(sample_x, dim=0)\n",
    "    var_x = torch.std(sample_x, dim=0)\n",
    "\n",
    "    var_y = Y.stddev\n",
    "\n",
    "    mu_y = Y.mean\n",
    "    \n",
    "    \n",
    "    return torch.mean(np.log(var_y/var_x) + (var_x**2 + (mu_x - mu_y)**2)/(2*var_y**2) -(1/2)), var_x, mu_x\n",
    "\n",
    "\n",
    "def calc_KL_1d(X, Y):\n",
    "    \n",
    "    sample_x = X.sample((1000,))\n",
    "    mu_x = torch.mean(sample_x, dim=0)\n",
    "    var_x = torch.std(sample_x, dim=0)\n",
    "    \n",
    "    print(var_x)\n",
    "    print(mu_x)\n",
    "\n",
    "\n",
    "    var_y = Y.stddev\n",
    "\n",
    "    mu_y = Y.mean\n",
    "    \n",
    "    print(mu_y)\n",
    "    print(var_y)\n",
    "    \n",
    "    print(np.log(var_y/var_x) + (var_x**2 + (mu_x - mu_y)**2)/(2*var_y**2) -(1/2))\n",
    "    \n",
    "    return np.log(var_y/var_x) + (var_x**2 + (mu_x - mu_y)**2)/(2*var_y**2) -(1/2)\n",
    "\n",
    "\n",
    "# calculate the jensen-shanon divergence\n",
    "def js_divergence(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c39fb7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c121919bbfb140e9b9b65d5a17f645ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9eaba8d39de45038ed63a4dc9417da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0052, 5.3878, 4.6121, 4.0123, 4.9192, 2.2973, 3.0643, 3.2328, 3.9826,\n",
      "        3.3701, 4.5230, 3.0755, 5.2773, 2.6041, 2.1775])\n",
      "tensor([ 8.6490, 10.4139, 21.0003,  9.4431, 82.2151, 52.4170, 34.0788, 26.8598,\n",
      "        10.4750, 66.4835,  8.6875, 64.8512, 89.2628, 41.8978, 46.5049])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[26.3710, 22.0712,  9.1074,  6.3148, 40.3082,  4.6430, 28.1302,  3.5619,\n",
      "         27.0115, 10.1468, 15.0182,  3.7657, 59.1683,  3.7343,  2.2249]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29aa52e9a324c989fe731574abea18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86a0926102044eb9379576c59a25f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8597, 5.3218, 5.5840, 5.4296, 4.6684, 2.8372, 3.9554, 3.2264, 4.0327,\n",
      "        3.2264, 5.5209, 3.3890, 2.8953, 3.1122, 2.4886])\n",
      "tensor([ 4.6527, 11.8572, 24.1122, 13.8919, 92.1315, 55.4455, 22.6598, 27.6212,\n",
      "         8.4611, 70.1690, 12.3387, 62.9723, 96.0146, 42.2285, 48.4439])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 3.9039, 29.1427, 21.8256, 20.1220, 11.1275,  2.5812, 15.3661,  3.7264,\n",
      "         16.1879,  3.5477, 39.9596,  8.6055,  7.0846,  5.6905,  7.6151]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b81fe74cfb14e56b682dc3dd5525f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c4360984ca4664bb71b3598022c8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4802, 3.7287, 3.2861, 4.2968, 3.5886, 2.0410, 2.8914, 3.1139, 3.8793,\n",
      "        2.2303, 4.3501, 2.8681, 3.5257, 1.7887, 2.5020])\n",
      "tensor([ 3.9095,  7.2795, 22.6315, 11.8387, 94.0944, 56.8993, 27.5352, 27.8070,\n",
      "        12.1807, 66.1515, 10.4362, 63.9445, 95.0845, 38.2387, 45.5661])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 2.0809,  5.9540,  7.1717,  8.9636, 13.0431,  2.6731,  2.7615,  3.5380,\n",
      "         39.1308,  8.5906, 22.2677,  4.6718, 12.1207,  2.0695,  1.8730]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58217621f9b4e949e9dd200f09d3af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33da877e17440bea7bcf4c6639aec91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5868, 3.3036, 2.6442, 5.2987, 2.8190, 1.6843, 3.7826, 3.1229, 3.5567,\n",
      "        2.4702, 3.9212, 2.5011, 3.4034, 2.6059, 2.9405])\n",
      "tensor([ 7.0546,  5.6077, 21.6002, 18.3668, 88.0503, 55.8696, 24.1828, 32.6074,\n",
      "         8.4382, 67.1821,  9.0244, 64.7060, 95.2903, 38.5164, 46.7261])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[12.8751,  3.8387,  3.3040, 46.8723,  4.3376,  0.7752,  9.2919, 18.9586,\n",
      "         14.4051,  5.6168, 13.9195,  2.5482, 10.9478,  3.0382,  4.2343]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0487a8b917d84009803144f12bad752e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ba0c70270b4284ad2d98ab2a3e9af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.4793, 4.8623, 3.4467, 3.8567, 3.8300, 1.9293, 3.1802, 2.8902, 4.7816,\n",
      "        3.2218, 5.7740, 3.0521, 5.1832, 2.5196, 2.5496])\n",
      "tensor([ 8.0315, 11.6874, 20.2573, 17.1612, 89.5685, 55.4891, 28.7070, 26.3372,\n",
      "        10.7931, 62.2082, 16.1786, 67.0404, 93.1195, 43.0275, 45.9648])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[20.6905, 25.9130,  4.2357, 31.2285,  5.5846,  0.8236,  4.8569,  2.8348,\n",
      "         32.4407, 33.8759, 76.8974,  3.5831, 28.5776,  6.3330,  2.2797]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01caf400d1c343c8ade7a8b6ec0949b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0898ed0fdd8d471e81a80e7b143975ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3029, 3.9389, 2.8148, 4.1539, 3.1945, 3.1226, 4.1319, 2.8671, 4.1684,\n",
      "        3.9777, 4.6842, 2.9797, 4.5512, 2.3408, 2.1597])\n",
      "tensor([ 7.3276,  7.3486, 22.2022, 10.8882, 89.0010, 52.5572, 33.2048, 30.8981,\n",
      "         9.3555, 65.8873, 12.3200, 63.0858, 92.2833, 41.8941, 44.6737])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[16.6623,  6.7959,  4.8515,  7.0977,  3.9400,  6.2203, 25.8672, 10.1546,\n",
      "         21.1014, 14.4874, 35.7176,  7.0936, 30.8980,  3.1831,  1.1154]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e69f8165b434f208a2f076b1fa28d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7223573da2e84ff782e9d1ab0f07ed54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1742, 4.2678, 3.6520, 5.0413, 5.4643, 2.7619, 4.5338, 3.1480, 5.2222,\n",
      "        2.3009, 5.3098, 3.2636, 3.3309, 3.0163, 2.6372])\n",
      "tensor([ 7.0572,  7.7226, 21.3012,  9.6074, 86.7005, 55.2397, 29.3720, 30.3851,\n",
      "        10.5771, 67.8753,  9.2966, 60.2296, 95.4062, 38.5189, 46.2528])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[15.0132,  8.6396,  5.7198, 10.6666, 18.1741,  2.3270, 11.0791,  9.0374,\n",
      "         33.1122,  3.5710, 21.1581, 20.2914, 10.3019,  4.0419,  2.7924]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5110d37e6f04427a8af87eaaacf4f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 904 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d00617a8654073a6545708d6635b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 396 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6649, 5.8475, 3.9929, 4.7433, 5.1628, 2.1785, 3.9148, 3.3838, 3.6039,\n",
      "        3.4572, 4.8985, 2.9318, 3.1012, 2.8619, 3.1291])\n",
      "tensor([ 5.8222, 13.4722, 26.4011, 11.9638, 91.7899, 58.7480, 26.8465, 23.6322,\n",
      "         6.1694, 76.3360,  8.6007, 61.1729, 95.9388, 42.0260, 44.4007])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 8.8992, 42.7477, 26.5742, 11.1209, 12.7875,  8.1181,  5.8100,  9.6773,\n",
      "          7.0649, 24.3078, 16.3913, 14.3725,  7.8624,  4.5961,  3.4346]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aeaa796e1164e54804c0d46e1af5f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d9c925feb94f05b93e33eab1264c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1338, 4.1292, 3.4119, 2.9949, 4.4737, 2.0436, 3.2658, 2.2322, 4.9168,\n",
      "        2.4445, 3.8080, 2.7398, 5.5360, 1.9873, 2.0323])\n",
      "tensor([ 5.7087, 10.2310, 21.9761, 12.8987, 85.1334, 56.8657, 31.1774, 30.1910,\n",
      "        10.6906, 66.5863,  7.0419, 65.0694, 89.1538, 39.6794, 47.0626])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 6.9369, 15.5578,  6.0457,  7.0889, 19.8507,  2.6140, 12.3745,  6.2796,\n",
      "         32.3770,  7.4208,  7.4982,  2.6784, 61.5856,  0.8393,  2.9832]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347ea48c148644318e154f1a663b799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c212d9b01f4e48b9bb07a959204a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5083, 3.3638, 3.2558, 3.3627, 4.1492, 2.1364, 2.8900, 2.7693, 3.9524,\n",
      "        3.0013, 7.2788, 4.0907, 3.6456, 2.4811, 1.9150])\n",
      "tensor([ 9.1407,  7.0696, 21.6730, 11.9383, 87.8225, 54.2458, 25.4552, 29.0992,\n",
      "         8.5803, 67.6099, 14.7887, 63.1547, 95.0790, 38.7394, 46.4265])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[23.2530,  4.5164,  5.0192,  5.8196,  9.0557,  1.3074,  3.8080,  4.5192,\n",
      "         16.4260,  5.7612, 71.9141, 10.5060, 12.5391,  2.4637,  1.7014]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4251f5059ba439e8d46888a095c16b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fe4bbb18ed496ba346f73f07c23780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6309, 3.7487, 3.9116, 5.1416, 3.7296, 2.7785, 3.5816, 3.4182, 4.0746,\n",
      "        2.3845, 3.8076, 2.6633, 3.7510, 2.4741, 2.2659])\n",
      "tensor([ 9.0809,  7.8278, 20.9229, 11.6188, 90.4591, 58.1332, 29.1895, 26.0161,\n",
      "         7.8463, 69.3232,  6.3224, 61.8246, 94.5159, 37.0046, 43.8296])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[23.2911,  6.8755,  6.2124, 12.3910,  5.2441,  7.2466,  7.0351,  4.5971,\n",
      "         13.7932,  1.7029,  6.2863, 10.7839, 15.2665,  6.1410,  1.9341]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb819d7710f4254bc215f5c268b3f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 1000 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3763822668194473babbb39a431937b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 999 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2790, 5.1593, 1.7369, 2.5827, 2.9758, 2.0675, 1.9363, 1.5997, 2.8807,\n",
      "        2.1223, 2.0976, 1.6069, 0.9146, 1.5824, 1.5719])\n",
      "tensor([ 2.4911, 11.1539, 23.6073,  5.7544, 89.3695, 57.8018, 30.2785, 29.2975,\n",
      "         5.7753, 66.4348,  5.5229, 64.1911, 99.0394, 40.2232, 46.4200])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[2.0136e-01, 2.4450e+01, 6.9626e+00, 1.0899e+01, 3.0360e+00, 4.8359e+00,\n",
      "         6.0881e+00, 2.9490e+00, 4.1672e+00, 7.3548e+00, 1.0959e+00, 1.9528e+00,\n",
      "         8.2962e-03, 3.1794e-01, 1.2914e+00]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5831f7571c194c5791e6e6070d343cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7153a7d9aeb64555858e9e92f3764ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9059, 4.3512, 4.0318, 3.5137, 3.7385, 2.8645, 3.8443, 2.9336, 5.0458,\n",
      "        3.3984, 4.2314, 2.5964, 2.8579, 2.6632, 2.8844])\n",
      "tensor([ 6.7179, 12.4371, 25.4154,  8.3625, 88.4886, 53.6374, 23.4351, 28.2311,\n",
      "        10.0016, 69.6760,  7.6560, 63.3555, 96.3856, 42.3676, 43.5934])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[12.6767, 28.2140, 20.8965,  5.7572,  6.3115,  3.4787, 11.8972,  3.4846,\n",
      "         28.6209,  4.1038, 10.5371,  5.4132,  5.9513,  4.8696,  3.5899]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba3380eedcc48b5be7d150da22de0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3928f7d5295d4af787b7a2550b34458d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8140, 5.9654, 4.2126, 4.2058, 4.4554, 2.3785, 2.7536, 3.1505, 3.6012,\n",
      "        2.4232, 4.9126, 3.4311, 5.9410, 2.5195, 2.8634])\n",
      "tensor([ 7.5029, 14.5072, 24.1854, 10.5302, 88.5598, 55.4220, 27.8618, 32.0941,\n",
      "         7.0305, 66.7874,  9.7065, 62.5234, 89.6679, 41.6580, 49.2756])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[15.5728, 51.6933, 15.6937,  7.0486,  8.9682,  1.5512,  2.6496, 16.2903,\n",
      "          9.2948,  6.7113, 21.0508, 10.1966, 58.9098,  3.1242, 11.6881]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1981b5afb04baf8d97d5e4df43d98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 995 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b43f2e252f14693a217a062558c99b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 990 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0374, 5.6740, 4.4099, 2.3368, 3.7264, 2.1660, 3.5793, 3.1281, 2.6364,\n",
      "        2.7130, 4.0687, 3.0406, 4.2868, 3.2225, 2.5575])\n",
      "tensor([ 4.9414, 11.2618, 20.4682,  4.0404, 91.7917, 57.3965, 30.0317, 24.5559,\n",
      "         4.3743, 67.0556,  7.2502, 65.1692, 94.7501, 40.1819, 47.0439])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 4.8863, 27.7046,  7.8492, 19.1399,  6.7325,  3.9444,  9.2263,  6.2389,\n",
      "          2.0760,  6.5170,  8.9054,  3.3557, 16.2634,  3.5386,  3.9202]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c5169a884743b0a67c91d5d47a690e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657a61300f7c4056b2d37c0ac4bc28c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3077, 3.3787, 2.5054, 3.2403, 3.8266, 1.8612, 3.1127, 2.9321, 3.8693,\n",
      "        2.8156, 3.3129, 2.7962, 3.7025, 2.1357, 1.6791])\n",
      "tensor([ 9.0214,  6.0001, 17.8279,  8.8052, 85.6584, 55.1647, 28.4963, 29.0256,\n",
      "         8.1903, 67.2206,  6.2869, 61.2977, 94.4177, 39.2987, 47.2369])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[25.4464,  3.9902,  4.0791,  4.2880, 14.9044,  0.6244,  4.3285,  4.7745,\n",
      "         14.4120,  6.2913,  4.6180, 13.4372, 15.5439,  1.2677,  2.8934]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61193ec66c84d53a01151740f1e752e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55914ff8e7ef4d5abddf339dba612726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8756, 3.7086, 2.9565, 3.3988, 4.2583, 1.9401, 3.3797, 2.7212, 3.4593,\n",
      "        3.4671, 3.3958, 2.0289, 5.2101, 2.2219, 1.5860])\n",
      "tensor([ 8.2834,  7.6616, 21.8163,  8.8751, 87.6477, 53.3898, 28.5939, 27.7698,\n",
      "         6.0866, 65.5726,  7.0816, 62.8727, 92.8127, 41.0964, 44.7285])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[19.6122,  6.4467,  4.4359,  4.6851,  9.8846,  2.0157,  5.2637,  2.4977,\n",
      "          6.4194, 14.0678,  6.2095,  5.7406, 30.5632,  1.7711,  0.3334]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df37aa26fc6c48389c5bf5988e0db35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 924 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849b4c018490433783ec4c4677ad1709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 920 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8488, 2.7059, 2.6770, 2.4018, 2.5117, 1.0209, 1.8077, 1.9217, 2.9271,\n",
      "        2.0880, 2.5017, 1.4260, 1.2290, 1.3924, 2.2924])\n",
      "tensor([ 5.7485,  8.7632, 24.1680, 14.2072, 96.6968, 54.7873, 25.4729, 27.0053,\n",
      "         6.6107, 66.7963,  4.6469, 64.0416, 98.6590, 36.9649, 51.7817])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[6.2880e+00, 5.9833e+00, 1.0784e+01, 1.0359e+01, 2.4157e+01, 2.3060e-02,\n",
      "         1.7077e+00, 6.9325e-01, 6.1179e+00, 6.0755e+00, 1.7747e+00, 2.0796e+00,\n",
      "         1.0713e-01, 4.7443e+00, 2.4294e+01]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3abbd0696e4199862e6e60d5ac1d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f231703b175e4ff0971d5a25c72f6f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5956, 4.2323, 3.6383, 4.6035, 4.9633, 2.0671, 3.3813, 4.7629, 4.4333,\n",
      "        3.6069, 4.3549, 3.1834, 4.0456, 2.8060, 2.3746])\n",
      "tensor([ 8.0197,  8.3917, 22.7379, 11.3051, 81.3139, 55.8138, 28.8273, 26.7663,\n",
      "         9.8138, 63.9101,  7.9217, 64.5993, 94.2875, 41.0084, 46.1802])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[17.2831,  9.8736,  8.5750,  9.4210, 47.9389,  1.2415,  5.6678,  9.3092,\n",
      "         24.7379, 23.2653, 11.7794,  4.3900, 17.3896,  2.9135,  2.1509]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c9c4c5d2f745788f1c114087e5967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da94d9b794f94184ad6b44005cfc71e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5702, 4.2131, 3.9048, 5.0969, 3.8470, 2.7822, 2.8224, 3.2223, 4.0188,\n",
      "        3.2844, 3.2632, 2.9894, 3.4714, 2.3822, 3.7635])\n",
      "tensor([11.0984,  8.2422, 23.4792, 10.0682, 89.8931, 56.9861, 24.3891, 29.5303,\n",
      "         6.9463, 66.3402,  6.0176, 65.6056, 95.5846, 40.3532, 43.6563])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[41.2157,  9.4504, 11.8140, 10.8627,  5.5582,  4.3194,  5.8538,  6.7228,\n",
      "         10.5248, 10.4014,  4.1594,  2.9509, 10.1131,  1.5317,  6.1594]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fe3474648c4b938d24f65a44e6dd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420c4af23dc648d680c783054d4a6fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0922, 3.5273, 3.2141, 4.1589, 4.1424, 2.4785, 2.7430, 3.3584, 4.0413,\n",
      "        3.2746, 2.6949, 2.8560, 3.0694, 2.1905, 2.3042])\n",
      "tensor([ 5.4771,  7.5233, 22.1804,  9.6342, 87.5287, 54.6684, 26.5838, 31.6442,\n",
      "        10.9864, 65.2191,  4.5888, 64.7355, 95.9775, 40.1158, 44.7729])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 6.2201,  5.6204,  5.8748,  6.7901,  9.7123,  1.7187,  2.3396, 14.7121,\n",
      "         30.6741, 15.1039,  2.2245,  3.3285,  7.6569,  1.1217,  1.3457]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d81b6d6ff4086983f570582783acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a71eb39a2bb4211a711e906c99b8a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5717, 3.7794, 3.4127, 3.9530, 4.1765, 1.5411, 2.6803, 2.9629, 4.1359,\n",
      "        2.1815, 3.4317, 2.7584, 2.9575, 2.2462, 1.7119])\n",
      "tensor([ 4.3891,  7.3512, 24.0114, 13.6423, 88.7338, 56.8258, 26.5775, 28.3125,\n",
      "        10.9706, 66.0934,  6.4551, 67.2466, 95.4256, 40.1056, 46.7097])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 2.8271,  6.2253, 12.1416, 12.5716,  7.5936,  1.9218,  2.1953,  3.6647,\n",
      "         30.9282,  8.7301,  5.2139,  3.0668,  9.1773,  1.2190,  1.8893]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a619faf5ce624a4fa000cc395df74d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 979 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf9ee930f54bc7857233b3021ade34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 975 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5210, 3.0285, 2.5255, 3.1359, 3.9999, 2.1786, 2.6264, 2.8428, 4.1387,\n",
      "        2.7560, 4.2003, 1.9580, 2.0320, 2.5958, 1.8864])\n",
      "tensor([ 7.4295,  6.5928, 21.6397, 10.0845, 87.5523, 54.8087, 26.7226, 28.0996,\n",
      "         8.3932, 65.8867,  9.5492, 63.1223, 97.7215, 38.4554, 46.6003])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[14.2500,  3.1535,  3.1070,  3.2775,  9.1087,  1.1127,  2.0218,  3.1004,\n",
      "         16.2943, 10.7435, 17.2336,  4.8854,  1.6728,  3.1081,  1.9250]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f488e93cdb34d8c9dd5cf5aa2bb3c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 910 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18d9b1152a94253b89b9bd08dbf9ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 905 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0507, 2.5020, 2.7317, 2.5209, 3.8376, 1.5449, 1.9642, 1.6941, 2.0867,\n",
      "        1.9063, 2.7371, 1.6742, 1.1364, 1.2856, 1.0888])\n",
      "tensor([ 2.2054,  8.4085, 20.5022, 10.4937, 92.6832, 55.4458, 27.5598, 28.7950,\n",
      "         4.7471, 68.5268,  7.2592, 66.0778, 98.6494, 38.7311, 46.5579])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0.3182, 4.6134, 2.3522, 1.8747, 9.1184, 0.3577, 0.9107, 2.0188, 1.2206,\n",
      "         1.7570, 4.7908, 0.3892, 0.0793, 0.8802, 1.2212]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6664fe5993194b1882a6a684a5faaba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 923 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e05ab0bef5d44fc8efab3f106980036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        1% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 904 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6482, 3.7066, 4.4282, 4.8394, 6.0726, 3.6644, 3.8033, 3.5419, 3.1743,\n",
      "        3.0888, 4.8987, 3.7985, 3.3049, 3.5863, 3.9773])\n",
      "tensor([ 9.4558,  6.2107, 21.2096, 14.9568, 84.3320, 55.2403, 28.6538, 26.7291,\n",
      "         5.3174, 69.3343, 11.2239, 62.6965, 96.0283, 39.0948, 46.2703])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[29.6053,  5.0816,  8.5482, 21.9181, 32.1977,  4.9442,  6.7643,  4.5447,\n",
      "          4.2507,  3.3641, 29.2783, 10.8364,  8.1815,  5.0633,  6.8359]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074436727575422a9c2a670dc6f69605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 1000 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5c018a1ee74ce98447ec538d487a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Drawing samples from posterior to estimate the normalizing\n",
      "                        constant for `log_prob()`. However, only\n",
      "                        0% posterior samples are within the\n",
      "                        prior support. It may take a long time to collect the\n",
      "                        remaining 998 samples.\n",
      "                        Consider interrupting (Ctrl-C) and either basing the\n",
      "                        estimate of the normalizing constant on fewer samples (by\n",
      "                        calling `posterior.leakage_correction(x_o,\n",
      "                        num_rejection_samples=N)`, where `N` is the number of\n",
      "                        samples you want to base the\n",
      "                        estimate on (default N=10000), or not estimating the\n",
      "                        normalizing constant at all\n",
      "                        (`log_prob(..., norm_posterior=False)`. The latter will\n",
      "                        result in an unnormalized `log_prob()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4588, 4.2242, 3.9787, 4.0522, 4.1708, 3.0663, 3.1740, 3.4698, 4.0643,\n",
      "        4.4470, 2.9152, 3.2912, 3.6250, 3.7813, 4.5207])\n",
      "tensor([ 3.9959,  7.2865, 22.6014,  8.7047, 93.1563, 55.8567, 24.5808, 30.2668,\n",
      "         7.6687, 67.7061,  4.5244, 62.2891, 95.3306, 38.5697, 39.7953])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 2.1191,  7.8084,  9.4178,  7.1497, 11.7508,  3.4475,  6.3083,  9.6117,\n",
      "         13.0868, 10.5266,  2.7924, 10.6102, 11.5147,  6.3419, 21.7541]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21374133ca55479d9b13e8c5de955aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6162524a351d47b4826b8cb3bcd03931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6736, 3.8224, 4.6071, 4.2923, 5.0553, 2.1881, 3.2422, 3.4572, 4.4770,\n",
      "        2.7374, 4.4494, 2.9503, 3.9440, 2.5236, 2.0487])\n",
      "tensor([10.0848,  9.7646, 24.9745, 13.6503, 85.1401, 55.5134, 26.8575, 29.4130,\n",
      "        15.2000, 64.9668, 13.9834, 60.2651, 92.8767, 40.7282, 44.2626])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[33.9767, 12.5504, 20.9581, 13.9174, 22.4670,  1.2427,  3.5900,  7.1469,\n",
      "         70.7424, 14.9063, 48.2563, 19.2150, 24.6531,  2.0237,  1.1534]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db12b58af1c4236a16a9ce8294838d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ea1dafe37142e5a90147203f5867f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8077, 4.0582, 3.7910, 4.9630, 4.5760, 2.4267, 3.6740, 3.5878, 4.1456,\n",
      "        2.8769, 5.2222, 3.0984, 3.3519, 2.4146, 2.7612])\n",
      "tensor([ 9.0928,  7.1757, 21.2395, 15.1520, 85.9127, 55.4593, 26.1734, 28.1168,\n",
      "         8.7905, 68.6534, 16.4776, 60.1587, 95.7112, 42.0529, 44.2501])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[23.9731,  7.0248,  6.1213, 23.4853, 16.8023,  1.6633,  5.2894,  5.2823,\n",
      "         18.1452,  3.4882, 77.3503, 20.2294,  9.3163,  3.6408,  2.5776]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855ab086a47946d2a835171d002c9d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e4b23c2af24d99a7d7d16a72fe301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0613, 3.2668, 2.9853, 5.0987, 4.7488, 2.1117, 3.0051, 3.6265, 5.6609,\n",
      "        3.1686, 4.9252, 2.2335, 2.8126, 2.8971, 2.4308])\n",
      "tensor([12.3929,  6.6296, 21.0781, 18.9179, 85.4350, 55.7397, 27.4863, 30.2748,\n",
      "        11.2429, 67.1705,  9.9669, 65.9338, 96.5919, 42.3750, 44.4685])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[60.1815,  3.8504,  3.4434, 50.6341, 19.6369,  1.2556,  3.0334, 10.1496,\n",
      "         40.0193,  7.3698, 22.3691,  1.1929,  5.3206,  5.4532,  1.7074]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac97f36917f47639e95c033087ac6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e1ddd69a2747d7a63d2aa7df452fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8828, 3.5982, 2.8951, 4.3164, 3.5506, 1.9925, 2.6127, 3.1953, 5.0621,\n",
      "        2.4246, 4.4952, 2.7931, 2.6978, 1.8379, 1.9843])\n",
      "tensor([ 4.3920,  9.3004, 20.2555, 20.1917, 84.8221, 54.5933, 24.0119, 27.2691,\n",
      "        12.6928, 67.7735, 10.5477, 60.9868, 96.3942, 40.1396, 43.7229])\n",
      "tensor([[ 3.,  6., 20., 10., 90., 55., 27., 27.,  4., 70.,  5., 66., 99., 40.,\n",
      "         45.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[ 3.5654, 10.1395,  2.6605, 59.2891, 17.9416,  0.8784,  6.4171,  3.4796,\n",
      "         48.4734,  4.0323, 23.4890, 14.9396,  5.5418,  0.5901,  1.5989]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "analytic = torch.distributions.normal.Normal(true_thetas, 1)\n",
    "\n",
    "\n",
    "overall_snpe_list = []\n",
    "\n",
    "variance_list_snpe = []\n",
    "\n",
    "mean_list_snpe = []\n",
    "\n",
    "\n",
    "## for round\n",
    "for posterior_snpe_list in list_collection:\n",
    "    \n",
    "    KL_snpe = []\n",
    "    KL_snpe_1d = []\n",
    "    \n",
    "    \n",
    "    ## for number of simulations\n",
    "    for posterior_snpe in posterior_snpe_list:\n",
    "\n",
    "\n",
    "        #KL = KLdivergence(posterior_snpe, sample_y)\n",
    "        KL, var_x, mu_x = KL_Gauss(posterior_snpe, analytic)\n",
    "        \n",
    "        variance_list_snpe.append(var_x)\n",
    "        \n",
    "        mean_list_snpe.append(mu_x)\n",
    "\n",
    "\n",
    "        KL_1d = calc_KL_1d(posterior_snpe, analytic)\n",
    "\n",
    "        KL_snpe_1d.append(KL_1d)\n",
    "\n",
    "        #KL_snpe_sum.append(sum_KL)\n",
    "\n",
    "        KL_snpe.append(KL)\n",
    "        \n",
    "    overall_snpe_list.append(KL_snpe)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f68ad23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0933dc46d4c248539bc94f7d6fbd56d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18c4d0ba6e741d5a0c428adc8d19e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe05aae368541b1b004ceb79b345c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c6873073e749e2b1a91b052b9a862d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a7de5f3e1c4d81be3846902eb85f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3480fa94ab1847a78a05c5f1eede8121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f94cab6b5e544c8a79de48b64e7b01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b11a5479a4244baa43bdde7ba4722d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1381a763f9974a6181259405fba1b42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4effcad42b024abba9f8fb709a60e5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9e5890498c4b8ea11773ceada5100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac3c6e7d4b548ea90f56404f2e536ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5affa7374fb4a69a78b4313b2fdae74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebca9f964bd4cdbb1ffbd8d1c605015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c621d75ca27406f947abbec78a434be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df44396a3e34059a3f78dd4daeebc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d293c833f6949319cf571146e742e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bfb3c3207c45d598cbf6136a9bc922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2d5beb08334d5ea373879356c2f8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e8d2309175488b87fa2af5ae5c9fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762367ab514844b9ade4b2d5d9c6cf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c283ff917e34b30b3cf3c4a4936deaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96afca60c4c546c59aeffb6c060436b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9762c0b6ca74459baecb8112638a82ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a4743483a849c18706e07caff3e1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4418904739b54774a3af399ff511106f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815ce0a4ce594842bf890fa53e5f35aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa0d8ff63da48ad84a9f7aaa42a70d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a34debdcdd64cb4923f0717881f17a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967bdb0d124d453e92e77de0df0ec020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000 posterior samples:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "np.random.seed(5)\n",
    "\n",
    "obs_real = Gaussian(true_thetas[0, 0:])\n",
    "\n",
    "\n",
    "\n",
    "analytic = torch.distributions.normal.Normal(true_thetas, 1)\n",
    "\n",
    "\n",
    "overall_incremental_list = []\n",
    "\n",
    "variance_list = []\n",
    "\n",
    "mean_list = []\n",
    "\n",
    "for posterior_incremental_list in list_collection_inc:\n",
    "    \n",
    "    KL_incremental = []\n",
    "\n",
    "    for posterior_incremental in posterior_incremental_list:\n",
    "\n",
    "        posterior_incremental.set_default_x(obs_real)\n",
    "\n",
    "        #KL = KLdivergence(posterior_incremental, sample_y)\n",
    "\n",
    "        KL, var_x, mu_x = KL_Gauss(posterior_incremental, analytic)\n",
    "        \n",
    "        variance_list.append(var_x)\n",
    "        mean_list.append(mu_x)\n",
    "\n",
    "        #KL_1d = calc_KL_1d(posterior_incremental, analytic)\n",
    "\n",
    "        #KL_incremental_1d.append(KL_1d)\n",
    "\n",
    "\n",
    "        KL_incremental.append(KL)\n",
    "\n",
    "        \n",
    "    overall_incremental_list.append(KL_incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a67366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_incremental = np.mean(np.array(overall_incremental_list), axis=0)\n",
    "\n",
    "\n",
    "stdev_incremental = np.std(np.array(overall_incremental_list), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "lower_incremental = mean_incremental - [element * 0.5 for element in stdev_incremental]\n",
    "\n",
    "upper_incremental = mean_incremental + [element * 0.5 for element in stdev_incremental]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babbcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70289653",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_snpe = np.mean(np.array(overall_snpe_list), axis=0)\n",
    "\n",
    "\n",
    "stdev_snpe = np.std(np.array(overall_snpe_list), axis=0)\n",
    "\n",
    "\n",
    "lower_snpe = mean_snpe - [element * 0.5 for element in stdev_snpe]\n",
    "\n",
    "upper_snpe = mean_snpe + [element * 0.5 for element in stdev_snpe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f0c3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations_list = [500, 750, 1000, 1500, 2000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e48db975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(num_simulations_list, mean_incremental, '-o',label='incremental', color='blue')\n",
    "plt.plot(num_simulations_list, mean_snpe, '-o', label='snpe', color='orange')\n",
    "\n",
    "plt.plot(num_simulations_list, upper_incremental, '--', color='blue')\n",
    "plt.plot(num_simulations_list, upper_snpe, '--',  color='orange')\n",
    "\n",
    "plt.plot(num_simulations_list, lower_incremental, '--',  color='blue')\n",
    "plt.plot(num_simulations_list, lower_snpe, '--',  color='orange')\n",
    "\n",
    "\n",
    "plt.fill_between(x= num_simulations_list, y1=lower_incremental, y2=upper_incremental, color='blue', alpha=0.2,  label='1 stdv')\n",
    "plt.fill_between(x= num_simulations_list, y1=lower_snpe, y2=upper_snpe, color='orange', alpha=0.2, label='1 stdv')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('simulations per round')\n",
    "plt.ylabel('KL divergence')\n",
    "\n",
    "sns.despine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5633279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
