{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e788d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path as op\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, jones_2009_model\n",
    "from hnn_core.viz import plot_dipole\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "\n",
    "from summary_features.calculate_summary_features import calculate_summary_statistics_alternative as extract_sumstats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c212ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining neuronal network model\n",
    "\n",
    "from utils.simulation_wrapper import event_seed, set_network_default, simulation_wrapper,simulation_wrapper_obs\n",
    "\n",
    "sim_wrapper = simulation_wrapper_obs\n",
    "\n",
    "net = set_network_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7d7fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"L2Basket_Gauss_A_weight\": 0.0,\n",
       "    \"L2Basket_Gauss_mu\": 2000.0,\n",
       "    \"L2Basket_Gauss_sigma\": 3.6,\n",
       "    \"L2Basket_Pois_A_weight_ampa\": 0.0,\n",
       "    \"L2Basket_Pois_A_weight_nmda\": 0.0,\n",
       "    \"L2Basket_Pois_lamtha\": 0.0,\n",
       "    \"L2Pyr_Gauss_A_weight\": 0.0,\n",
       "    \"L2Pyr_Gauss_mu\": 2000.0,\n",
       "    \"L2Pyr_Gauss_sigma\": 3.6,\n",
       "    \"L2Pyr_Pois_A_weight_ampa\": 0.0,\n",
       "    \"L2Pyr_Pois_A_weight_nmda\": 0.0,\n",
       "    \"L2Pyr_Pois_lamtha\": 0.0,\n",
       "    \"L2Pyr_ampa_e\": 0.0,\n",
       "    \"L2Pyr_ampa_tau1\": 0.5,\n",
       "    \"L2Pyr_ampa_tau2\": 5.0,\n",
       "    \"L2Pyr_apical1_L\": 306.0,\n",
       "    \"L2Pyr_apical1_diam\": 4.08,\n",
       "    \"L2Pyr_apicaloblique_L\": 340.0,\n",
       "    \"L2Pyr_apicaloblique_diam\": 3.91,\n",
       "    \"L2Pyr_apicaltrunk_L\": 59.5,\n",
       "    \"L2Pyr_apicaltrunk_diam\": 4.25,\n",
       "    \"L2Pyr_apicaltuft_L\": 238.0,\n",
       "    \"L2Pyr_apicaltuft_diam\": 3.4,\n",
       "    \"L2Pyr_basal1_L\": 85.0,\n",
       "    \"L2Pyr_basal1_diam\": 4.25,\n",
       "    \"L2Pyr_basal2_L\": 255.0,\n",
       "    \"L2Pyr_basal2_diam\": 2.72,\n",
       "    \"L2Pyr_basal3_L\": 255.0,\n",
       "    \"L2Pyr_basal3_diam\": 2.72,\n",
       "    \"L2Pyr_dend_Ra\": 200.0,\n",
       "    \"L2Pyr_dend_cm\": 0.6195,\n",
       "    \"L2Pyr_dend_el_hh2\": -65.0,\n",
       "    \"L2Pyr_dend_gbar_km\": 250.0,\n",
       "    \"L2Pyr_dend_gkbar_hh2\": 0.01,\n",
       "    \"L2Pyr_dend_gl_hh2\": 4.26e-05,\n",
       "    \"L2Pyr_dend_gnabar_hh2\": 0.15,\n",
       "    \"L2Pyr_gabaa_e\": -80.0,\n",
       "    \"L2Pyr_gabaa_tau1\": 0.5,\n",
       "    \"L2Pyr_gabaa_tau2\": 5.0,\n",
       "    \"L2Pyr_gabab_e\": -80.0,\n",
       "    \"L2Pyr_gabab_tau1\": 1.0,\n",
       "    \"L2Pyr_gabab_tau2\": 20.0,\n",
       "    \"L2Pyr_nmda_e\": 0.0,\n",
       "    \"L2Pyr_nmda_tau1\": 1.0,\n",
       "    \"L2Pyr_nmda_tau2\": 20.0,\n",
       "    \"L2Pyr_soma_L\": 22.1,\n",
       "    \"L2Pyr_soma_Ra\": 200.0,\n",
       "    \"L2Pyr_soma_cm\": 0.6195,\n",
       "    \"L2Pyr_soma_diam\": 23.4,\n",
       "    \"L2Pyr_soma_el_hh2\": -65.0,\n",
       "    \"L2Pyr_soma_gbar_km\": 250.0,\n",
       "    \"L2Pyr_soma_gkbar_hh2\": 0.01,\n",
       "    \"L2Pyr_soma_gl_hh2\": 4.26e-05,\n",
       "    \"L2Pyr_soma_gnabar_hh2\": 0.18,\n",
       "    \"L5Basket_Gauss_A_weight\": 0.0,\n",
       "    \"L5Basket_Gauss_mu\": 2000.0,\n",
       "    \"L5Basket_Gauss_sigma\": 2.0,\n",
       "    \"L5Basket_Pois_A_weight_ampa\": 0.0,\n",
       "    \"L5Basket_Pois_A_weight_nmda\": 0.0,\n",
       "    \"L5Basket_Pois_lamtha\": 0.0,\n",
       "    \"L5Pyr_Gauss_A_weight\": 0.0,\n",
       "    \"L5Pyr_Gauss_mu\": 2000.0,\n",
       "    \"L5Pyr_Gauss_sigma\": 4.8,\n",
       "    \"L5Pyr_Pois_A_weight_ampa\": 0.0,\n",
       "    \"L5Pyr_Pois_A_weight_nmda\": 0.0,\n",
       "    \"L5Pyr_Pois_lamtha\": 0.0,\n",
       "    \"L5Pyr_ampa_e\": 0.0,\n",
       "    \"L5Pyr_ampa_tau1\": 0.5,\n",
       "    \"L5Pyr_ampa_tau2\": 5.0,\n",
       "    \"L5Pyr_apical1_L\": 680.0,\n",
       "    \"L5Pyr_apical1_diam\": 7.48,\n",
       "    \"L5Pyr_apical2_L\": 680.0,\n",
       "    \"L5Pyr_apical2_diam\": 4.93,\n",
       "    \"L5Pyr_apicaloblique_L\": 255.0,\n",
       "    \"L5Pyr_apicaloblique_diam\": 5.1,\n",
       "    \"L5Pyr_apicaltrunk_L\": 102.0,\n",
       "    \"L5Pyr_apicaltrunk_diam\": 10.2,\n",
       "    \"L5Pyr_apicaltuft_L\": 425.0,\n",
       "    \"L5Pyr_apicaltuft_diam\": 3.4,\n",
       "    \"L5Pyr_basal1_L\": 85.0,\n",
       "    \"L5Pyr_basal1_diam\": 6.8,\n",
       "    \"L5Pyr_basal2_L\": 255.0,\n",
       "    \"L5Pyr_basal2_diam\": 8.5,\n",
       "    \"L5Pyr_basal3_L\": 255.0,\n",
       "    \"L5Pyr_basal3_diam\": 8.5,\n",
       "    \"L5Pyr_dend_Ra\": 200.0,\n",
       "    \"L5Pyr_dend_cm\": 0.85,\n",
       "    \"L5Pyr_dend_el_hh2\": -71.0,\n",
       "    \"L5Pyr_dend_gbar_ar\": 1e-06,\n",
       "    \"L5Pyr_dend_gbar_ca\": 60.0,\n",
       "    \"L5Pyr_dend_gbar_cat\": 0.0002,\n",
       "    \"L5Pyr_dend_gbar_kca\": 0.0002,\n",
       "    \"L5Pyr_dend_gbar_km\": 200.0,\n",
       "    \"L5Pyr_dend_gkbar_hh2\": 0.01,\n",
       "    \"L5Pyr_dend_gl_hh2\": 4.26e-05,\n",
       "    \"L5Pyr_dend_gnabar_hh2\": 0.14,\n",
       "    \"L5Pyr_dend_taur_cad\": 20.0,\n",
       "    \"L5Pyr_gabaa_e\": -80.0,\n",
       "    \"L5Pyr_gabaa_tau1\": 0.5,\n",
       "    \"L5Pyr_gabaa_tau2\": 5.0,\n",
       "    \"L5Pyr_gabab_e\": -80.0,\n",
       "    \"L5Pyr_gabab_tau1\": 1.0,\n",
       "    \"L5Pyr_gabab_tau2\": 20.0,\n",
       "    \"L5Pyr_nmda_e\": 0.0,\n",
       "    \"L5Pyr_nmda_tau1\": 1.0,\n",
       "    \"L5Pyr_nmda_tau2\": 20.0,\n",
       "    \"L5Pyr_soma_L\": 39.0,\n",
       "    \"L5Pyr_soma_Ra\": 200.0,\n",
       "    \"L5Pyr_soma_cm\": 0.85,\n",
       "    \"L5Pyr_soma_diam\": 28.9,\n",
       "    \"L5Pyr_soma_el_hh2\": -65.0,\n",
       "    \"L5Pyr_soma_gbar_ar\": 1e-06,\n",
       "    \"L5Pyr_soma_gbar_ca\": 60.0,\n",
       "    \"L5Pyr_soma_gbar_cat\": 0.0002,\n",
       "    \"L5Pyr_soma_gbar_kca\": 0.0002,\n",
       "    \"L5Pyr_soma_gbar_km\": 200.0,\n",
       "    \"L5Pyr_soma_gkbar_hh2\": 0.01,\n",
       "    \"L5Pyr_soma_gl_hh2\": 4.26e-05,\n",
       "    \"L5Pyr_soma_gnabar_hh2\": 0.16,\n",
       "    \"L5Pyr_soma_taur_cad\": 20.0,\n",
       "    \"N_pyr_x\": 10,\n",
       "    \"N_pyr_y\": 10,\n",
       "    \"N_trials\": 1,\n",
       "    \"T_pois\": -1,\n",
       "    \"celsius\": 37.0,\n",
       "    \"dipole_scalefctr\": 3000,\n",
       "    \"dipole_smooth_win\": 30,\n",
       "    \"distribution_dist\": \"normal\",\n",
       "    \"distribution_prox\": \"normal\",\n",
       "    \"dt\": 0.025,\n",
       "    \"dt_evprox0_evdist\": -1,\n",
       "    \"dt_evprox0_evprox1\": -1,\n",
       "    \"events_per_cycle_dist\": 2,\n",
       "    \"events_per_cycle_prox\": 2,\n",
       "    \"f_input_dist\": 10.0,\n",
       "    \"f_input_prox\": 10.0,\n",
       "    \"f_max_spec\": 100,\n",
       "    \"f_stdev_dist\": 20.0,\n",
       "    \"f_stdev_prox\": 20.0,\n",
       "    \"gbar_L2Basket_L2Basket\": 0.02,\n",
       "    \"gbar_L2Basket_L2Pyr_gabaa\": 0.05,\n",
       "    \"gbar_L2Basket_L2Pyr_gabab\": 0.05,\n",
       "    \"gbar_L2Basket_L5Pyr\": 0.001,\n",
       "    \"gbar_L2Pyr_L2Basket\": 0.0005,\n",
       "    \"gbar_L2Pyr_L2Pyr_ampa\": 0.0005,\n",
       "    \"gbar_L2Pyr_L2Pyr_nmda\": 0.0005,\n",
       "    \"gbar_L2Pyr_L5Basket\": 0.00025,\n",
       "    \"gbar_L2Pyr_L5Pyr\": 0.00025,\n",
       "    \"gbar_L5Basket_L5Basket\": 0.02,\n",
       "    \"gbar_L5Basket_L5Pyr_gabaa\": 0.025,\n",
       "    \"gbar_L5Basket_L5Pyr_gabab\": 0.025,\n",
       "    \"gbar_L5Pyr_L5Basket\": 0.0005,\n",
       "    \"gbar_L5Pyr_L5Pyr_ampa\": 0.0005,\n",
       "    \"gbar_L5Pyr_L5Pyr_nmda\": 0.0005,\n",
       "    \"gbar_evdist_1_L2Basket_ampa\": 0.006562,\n",
       "    \"gbar_evdist_1_L2Basket_nmda\": 0.019482,\n",
       "    \"gbar_evdist_1_L2Pyr_ampa\": 7e-06,\n",
       "    \"gbar_evdist_1_L2Pyr_nmda\": 0.004317,\n",
       "    \"gbar_evdist_1_L5Pyr_ampa\": 0.1423,\n",
       "    \"gbar_evdist_1_L5Pyr_nmda\": 0.080074,\n",
       "    \"gbar_evprox_1_L2Basket_ampa\": 0.08831,\n",
       "    \"gbar_evprox_1_L2Basket_nmda\": 0.0,\n",
       "    \"gbar_evprox_1_L2Pyr_ampa\": 0.01525,\n",
       "    \"gbar_evprox_1_L2Pyr_nmda\": 0.0,\n",
       "    \"gbar_evprox_1_L5Basket_ampa\": 0.19934,\n",
       "    \"gbar_evprox_1_L5Basket_nmda\": 0.0,\n",
       "    \"gbar_evprox_1_L5Pyr_ampa\": 0.00865,\n",
       "    \"gbar_evprox_1_L5Pyr_nmda\": 0.0,\n",
       "    \"gbar_evprox_2_L2Basket_ampa\": 3e-06,\n",
       "    \"gbar_evprox_2_L2Basket_nmda\": 0.0,\n",
       "    \"gbar_evprox_2_L2Pyr_ampa\": 1.43884,\n",
       "    \"gbar_evprox_2_L2Pyr_nmda\": 0.0,\n",
       "    \"gbar_evprox_2_L5Basket_ampa\": 0.008958,\n",
       "    \"gbar_evprox_2_L5Basket_nmda\": 0.0,\n",
       "    \"gbar_evprox_2_L5Pyr_ampa\": 0.684013,\n",
       "    \"gbar_evprox_2_L5Pyr_nmda\": 0.0,\n",
       "    \"inc_evinput\": 0.0,\n",
       "    \"input_dist_A_delay_L2\": 5.0,\n",
       "    \"input_dist_A_delay_L5\": 5.0,\n",
       "    \"input_dist_A_weight_L2Basket_ampa\": 0.0,\n",
       "    \"input_dist_A_weight_L2Basket_nmda\": 0.0,\n",
       "    \"input_dist_A_weight_L2Pyr_ampa\": 0.0,\n",
       "    \"input_dist_A_weight_L2Pyr_nmda\": 0.0,\n",
       "    \"input_dist_A_weight_L5Pyr_ampa\": 0.0,\n",
       "    \"input_dist_A_weight_L5Pyr_nmda\": 0.0,\n",
       "    \"input_prox_A_delay_L2\": 0.1,\n",
       "    \"input_prox_A_delay_L5\": 1.0,\n",
       "    \"input_prox_A_weight_L2Basket_ampa\": 0.0,\n",
       "    \"input_prox_A_weight_L2Basket_nmda\": 0.0,\n",
       "    \"input_prox_A_weight_L2Pyr_ampa\": 0.0,\n",
       "    \"input_prox_A_weight_L2Pyr_nmda\": 0.0,\n",
       "    \"input_prox_A_weight_L5Basket_ampa\": 0.0,\n",
       "    \"input_prox_A_weight_L5Basket_nmda\": 0.0,\n",
       "    \"input_prox_A_weight_L5Pyr_ampa\": 0.0,\n",
       "    \"input_prox_A_weight_L5Pyr_nmda\": 0.0,\n",
       "    \"numspikes_evdist_1\": 1,\n",
       "    \"numspikes_evprox_1\": 1,\n",
       "    \"numspikes_evprox_2\": 1,\n",
       "    \"prng_seedcore_evdist_1\": 2,\n",
       "    \"prng_seedcore_evprox_1\": 2,\n",
       "    \"prng_seedcore_evprox_2\": 2,\n",
       "    \"prng_seedcore_extgauss\": 2,\n",
       "    \"prng_seedcore_extpois\": 2,\n",
       "    \"prng_seedcore_input_dist\": 2,\n",
       "    \"prng_seedcore_input_prox\": 2,\n",
       "    \"record_isoma\": 0,\n",
       "    \"record_vsoma\": 0,\n",
       "    \"repeats_dist\": 10,\n",
       "    \"repeats_prox\": 10,\n",
       "    \"save_dpl\": 0,\n",
       "    \"save_figs\": 0,\n",
       "    \"save_spec_data\": 0,\n",
       "    \"sigma_t_evdist_1\": 3.85,\n",
       "    \"sigma_t_evprox_1\": 2.47,\n",
       "    \"sigma_t_evprox_2\": 8.33,\n",
       "    \"sim_prefix\": \"default\",\n",
       "    \"spec_cmap\": \"jet\",\n",
       "    \"sync_evinput\": false,\n",
       "    \"t0_input_dist\": 1000,\n",
       "    \"t0_input_prox\": 1000.0,\n",
       "    \"t0_input_stdev_dist\": 0.0,\n",
       "    \"t0_input_stdev_prox\": 0.0,\n",
       "    \"t0_pois\": 0.0,\n",
       "    \"t_evdist_1\": 63.53,\n",
       "    \"t_evprox_1\": 26.61,\n",
       "    \"t_evprox_2\": 137.12,\n",
       "    \"threshold\": 0.0,\n",
       "    \"tstop\": 170,\n",
       "    \"tstop_input_dist\": 1001,\n",
       "    \"tstop_input_prox\": 1001\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 30\n",
    "prior_min = [7.9, 43.8]   # 't_evdist_1', 'sigma_t_evdist_1', 't_evprox_2', 'sigma_t_evprox_2'\n",
    "\n",
    "prior_max = [30, 79.9]  \n",
    "\n",
    "prior = utils.torchutils.BoxUniform(low=prior_min, \n",
    "                                    high=prior_max)\n",
    "\n",
    "number_simulations = 8\n",
    "density_estimator = 'nsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5528677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert (prior.event_shape==torch.Size([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230edc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "params size torch.Size([2, 2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/envs/sbi_env/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8543f4b25242969185cea4fdcf410a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 8 simulations in 8 batches.:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import inference\n",
    "from utils.simulation_wrapper import event_seed, simulation_wrapper\n",
    "\n",
    "\n",
    "## define number of summary statistics\n",
    "\n",
    "sum_stats_number = 6\n",
    "number_stats = 6\n",
    "\n",
    "#posterior, theta, x, x_without = inference.run_sim_inference(prior, \n",
    "#                                                             sim_wrapper,\n",
    "#                                                             calc_sum_stats=extract_sumstats,\n",
    "#                                                             sum_stats_number = sum_stats_number,\n",
    "#                                                             num_simulations=number_simulations, \n",
    "#                                                             density_estimator=density_estimator, \n",
    "#                                                             num_workers=8)\n",
    "\n",
    "theta, x_without = inference.run_sim_theta_x(\n",
    "            prior, \n",
    "            sim_wrapper,\n",
    "            num_simulations = number_simulations,\n",
    "            num_workers = 8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de832d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_sumstats(x_without, number_stats)\n",
    "\n",
    "window_len, scaling_factor = 30, 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6e2f6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa9f4a14",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of parameter sets (=8 must match the number of simulation outputs (=100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236212/1829182878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSNPE_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nsf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_simulations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sbi/inference/snpe/snpe_base.py\u001b[0m in \u001b[0;36mappend_simulations\u001b[0;34m(self, theta, x, proposal)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \"\"\"\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_theta_and_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sbi/utils/user_input_checks.py\u001b[0m in \u001b[0;36mvalidate_theta_and_x\u001b[0;34m(theta, x, training_device)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Simulator output must be a `torch.Tensor`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     assert theta.shape[0] == x.shape[0], (\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;34mf\"Number of parameter sets (={theta.shape[0]} must match the number of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;34mf\"simulation outputs (={x.shape[0]})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Number of parameter sets (=8 must match the number of simulation outputs (=100)"
     ]
    }
   ],
   "source": [
    "from sbi.inference import SNPE_C\n",
    "\n",
    "inf = SNPE_C(prior, density_estimator=\"nsf\")\n",
    "\n",
    "inf = inf.append_simulations(theta, x)\n",
    "\n",
    "\n",
    "density_estimator = inf.train()\n",
    "\n",
    "posterior = inf.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c143899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23a87164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load_writer import write_to_file\n",
    "\n",
    "import os\n",
    "experiment_name = 'alternative_sum_stats_500sim_2params'\n",
    "true_params = [26.6, 63.53]\n",
    "\n",
    "#os.mkdir('results')\n",
    "\n",
    "\n",
    "num_samples = 100\n",
    "file_writer = write_to_file.WriteToFile(\n",
    "    experiment=experiment_name,\n",
    "    num_sim=number_simulations,\n",
    "    true_params=true_params,\n",
    "    density_estimator='nsf',\n",
    "    num_params=2,\n",
    "    num_samples=num_samples,\n",
    "    )\n",
    "\n",
    "os.mkdir('results/{}/step1'.format(experiment_name))\n",
    "\n",
    "\n",
    "file_writer.save_posterior(posterior)\n",
    "file_writer.save_observations(x, name='step1')\n",
    "\n",
    "file_writer.save_obs_without(x_without, name='step1')\n",
    "file_writer.save_thetas(theta, name='step1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1e71152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Building the NEURON model\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "\n",
      "Simulation time: 20.0 ms...\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...2\n",
      "params size torch.Size([2])\n",
      "2 params are investigated\n",
      "joblib will run over 1 jobs\n",
      "Loading custom mechanism files from /home/ubuntu/miniconda3/lib/python3.9/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so\n",
      "Building the NEURON model\n",
      "[Done]\n",
      "running trial 1 on 1 cores\n",
      "Simulation time: 0.03 ms...\n",
      "Simulation time: 10.0 ms...\n",
      "Simulation time: 20.0 ms...\n",
      "Simulation time: 30.0 ms...\n",
      "Simulation time: 40.0 ms...\n",
      "Simulation time: 50.0 ms...\n",
      "Simulation time: 60.0 ms...\n",
      "Simulation time: 70.0 ms...\n",
      "Simulation time: 80.0 ms...\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "\n",
      "Simulation time: 90.0 ms...\n",
      "Simulation time: 100.0 ms...\n",
      "Simulation time: 110.0 ms...\n",
      "Simulation time: 120.0 ms...\n",
      "Simulation time: 130.0 ms...\n",
      "Simulation time: 140.0 ms...\n",
      "Simulation time: 150.0 ms...\n",
      "Simulation time: 160.0 ms...\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.7s finished\n"
     ]
    }
   ],
   "source": [
    "true_params = torch.tensor([[26.6, 63.53]])\n",
    "obs_real = inference.run_only_sim(true_params, sim_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ee4e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-0.5976, -0.5984, -0.5992,  ...,  7.6487,  7.6247,  7.6007],\n",
      "       dtype=torch.float64)]\n",
      "torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b8b8ebffa34bbdbf232eeef566bf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 100 posterior samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (6801) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236212/3480998060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_real_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sbi/inference/posteriors/direct_posterior.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, x, show_progress_bars, sample_with, mcmc_method, mcmc_parameters, rejection_sampling_parameters, sample_with_mcmc)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;31m# that are outside of the prior support. This can be considered as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;31m# rejection sampling with a very good proposal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 samples = utils.rejection_sample_posterior_within_prior(\n\u001b[0m\u001b[1;32m    389\u001b[0m                     \u001b[0mposterior_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sbi/utils/sbiutils.py\u001b[0m in \u001b[0;36mrejection_sample_posterior_within_prior\u001b[0;34m(posterior_nn, prior, x, num_samples, show_progress_bars, warn_acceptance, sample_for_correction_factor, max_sampling_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# Sample and reject.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         candidates = posterior_nn.sample(sampling_batch_size, context=x).reshape(\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0msampling_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/nflows/distributions/base.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_samples, context, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/nflows/flows/base.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, num_samples, context)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0membedded_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sbi/utils/sbiutils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (6801) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(obs_real)\n",
    "obs_real_stats = extract_sumstats(obs_real[0], number_stats)\n",
    "\n",
    "print(obs_real_stats.shape)\n",
    "\n",
    "\n",
    "samples = posterior.sample((num_samples,), x=obs_real_stats)\n",
    "\n",
    "\n",
    "samples_prior = []\n",
    "\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = prior.sample()\n",
    "    samples_prior.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "num_workers = 8\n",
    "#x_lin = torch.arange(0,10,0.01, dtype= torch.float32)\n",
    "s_x = inference.run_only_sim(samples, sim_wrapper, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e07962",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x_prior = inference.run_only_sim(samples_prior, sim_wrapper, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x_stat = extract_sumstats(s_x, number_stats)\n",
    "\n",
    "s_x_prior_stat = extract_sumstats(s_x_prior, number_stats)\n",
    "\n",
    "\n",
    "print(s_x_stats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cddd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(\"Simulating from posterior\")\n",
    "for s in s_x:\n",
    "    plt.plot(s, alpha=0.1, color='blue')\n",
    "    #plt.ylim(-30,30)\n",
    "    plt.xlim(0, 7000)\n",
    "plt.plot(obs_real[0], label='Ground truth', color='red')\n",
    "#plt.legend()\n",
    "    \n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(\"Simulating from prior\")\n",
    "for x_w in s_x_prior:\n",
    "    plt.plot(x_w, alpha=0.1, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,40), tight_layout=True)\n",
    "\n",
    "gs = gridspec.GridSpec(nrows=x.size(dim=1), ncols=1)\n",
    "print(len(s_x_stat[0]))\n",
    "\n",
    "sum_stats_names = torch.arange(1, len(s_x_stat[0])+1, 1)\n",
    "\n",
    "print(sum_stats_names)\n",
    "\n",
    "\n",
    "\n",
    "#fig.suptitle('Summary stats histogram from posterior predictions.', y=0.2, fontsize=16)\n",
    "\n",
    "\n",
    "for i in range(len(sum_stats_names)):\n",
    "\n",
    "    globals()['ax%s' % i] = fig.add_subplot(gs[i])\n",
    "\n",
    "    globals()['sum_stats%s' % i] = []\n",
    "    globals()['x%s' % i] = []\n",
    "\n",
    "    for j in range(len(s_x)):\n",
    "        globals()['sum_stats%s' % i].append(s_x_stat[j][i])\n",
    "        globals()['x%s' % i].append(s_x_prior_stat[j][i])\n",
    "\n",
    "\n",
    "\n",
    "    globals()['ax%s' % i].hist(globals()['sum_stats%s' % i],  density=False, facecolor='g', alpha=0.75, histtype='barstacked', label='from posterior')\n",
    "    globals()['ax%s' % i].hist(globals()['x%s' % i],  density=False, facecolor='b', alpha=0.5, histtype='barstacked', label='simulated')\n",
    "    \n",
    "  \n",
    "    globals()['ax%s' % i].set_title('Histogram of summary stat \"{}\" '.format(sum_stats_names[i]), pad=20)\n",
    "    #ax0.set(ylim=(-500, 7000))\n",
    "\n",
    "    globals()['ax%s' % i].axvline(obs_real_stats[0][i], color='red', label='ground truth')\n",
    "    globals()['ax%s' % i].legend(loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('Summary_stats_post_prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc167a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = torch.Tensor([26.6, 63.53])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           #limits=[[.5,80], [1e-4,15.]],\n",
    "                           #ticks=[[.5,80], [1e-4,15.]],\n",
    "                           figsize=(5,5),\n",
    "                           points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           points_colors='r');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
